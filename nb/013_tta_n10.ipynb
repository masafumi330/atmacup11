{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"013_tta_n10.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0YiMk3wN_jhr"},"source":["### 基本の設定"]},{"cell_type":"markdown","metadata":{"id":"XGLHzEGE_jhr"},"source":["### Seed の固定\n","\n","再現性を取るため"]},{"cell_type":"code","metadata":{"id":"s-sS-I3fAE7I","executionInfo":{"status":"ok","timestamp":1626347932976,"user_tz":-540,"elapsed":345,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCwmBKH2_jhr","executionInfo":{"status":"ok","timestamp":1626347935853,"user_tz":-540,"elapsed":2530,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["import os\n","import random\n","\n","import numpy as np\n","import torch\n","\n","\n","def seed_torch(seed=330):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print(\"*** os.environ['PYTHONHASHSEED']  = \", os.environ['PYTHONHASHSEED'])\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_torch\n","\n","import matplotlib.pyplot as plt\n","\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","from glob import  glob"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eb1pS3yy_jht"},"source":["### 各種ディレクトリの定義"]},{"cell_type":"code","metadata":{"id":"w1aRT7_b_jht","executionInfo":{"status":"ok","timestamp":1626347938043,"user_tz":-540,"elapsed":2193,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["dataset_root = '/content/drive/MyDrive/atmacup11/'\n","assert dataset_root is not None\n","\n","input_dir = os.path.join(dataset_root, \"datasets\")\n","photo_dir = os.path.join(input_dir, \"photos\")\n","\n","output_dir = os.path.join(dataset_root, \"outputs_nb010\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","train_df = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n","test_df = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n","\n","material_df = pd.read_csv(os.path.join(input_dir, 'materials.csv'))\n","technique_df = pd.read_csv(os.path.join(input_dir, 'techniques.csv'))\n","\n","RANDOM_SEED = 330"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdkvoCra_jhu","executionInfo":{"status":"ok","timestamp":1626347938044,"user_tz":-540,"elapsed":5,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["class Config:\n","    N_FOLDS = 5\n","    N_EPOCHS = 100"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T4MaiodHUC8a"},"source":["### StratifiedGroupKFoldの実装"]},{"cell_type":"code","metadata":{"id":"xdqZtaDHWjrX","executionInfo":{"status":"ok","timestamp":1626347938527,"user_tz":-540,"elapsed":486,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["import random\n","from sklearn.model_selection import GroupKFold\n","from collections import Counter, defaultdict\n","\n","\n","def Count_y(y, groups):\n","    # y counts per group\n","    unique_num = np.max(y) + 1\n","    y_counts_per_group = defaultdict(lambda: np.zeros(unique_num))\n","    for label, g in zip(y, groups):\n","        y_counts_per_group[g][label] += 1\n","\n","    return y_counts_per_group\n","\n","\n","def StratifiedGroupKFold(X, y, groups, features, k, seed = None):\n","    # Preparation\n","    max_y = np.max(y)\n","    y_counts_per_group = Count_y(y, groups)\n","    kf = GroupKFold(n_splits=k)\n","\n","    for train_idx, val_idx in kf.split(X, y, groups):\n","        # Training dataset and validation dataset\n","        x_train = X.iloc[train_idx, :]\n","        id_train = x_train[\"art_series_id\"].unique()\n","        x_train = x_train[features]\n","\n","        x_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n","        id_val = x_val[\"art_series_id\"].unique()\n","        x_val = x_val[features]\n","\n","        # y counts of training dataset and validation dataset\n","        y_counts_train = np.zeros(max_y+1)\n","        y_counts_val = np.zeros(max_y+1)\n","        for id_ in id_train:\n","            y_counts_train += y_counts_per_group[id_]\n","        for id_ in id_val:\n","            y_counts_val += y_counts_per_group[id_]\n","\n","        # Determination ratio of validation dataset\n","        numratio_train = y_counts_train / np.max(y_counts_train)\n","        stratified_count = np.ceil(y_counts_val[np.argmax(y_counts_train)] * numratio_train)\n","        stratified_count = stratified_count.astype(int)\n","\n","        # Select validation dataset randomly\n","        val_idx = np.array([])\n","        np.random.seed(seed) \n","        for num in range(max_y+1):\n","            val_idx = np.append(val_idx, np.random.choice(y_val[y_val==num].index, stratified_count[num]))\n","        val_idx = val_idx.astype(int)\n","        \n","        yield train_idx, val_idx"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNaZBVJn_jhu"},"source":["### 画像データの読み込み"]},{"cell_type":"code","metadata":{"id":"do_GJ6jb_jhu","executionInfo":{"status":"ok","timestamp":1626347938932,"user_tz":-540,"elapsed":408,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["from PIL import Image\n","\n","def to_img_path(object_id):\n","    return os.path.join(photo_dir, f'{object_id}.jpg')\n","\n","def read_image(object_id):\n","    return Image.open(to_img_path(object_id))\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.optim.optimizer import Optimizer\n","from torch.utils import data\n","\n","# torchvision\n","from torchvision import transforms as T\n","from torchvision.models import resnet34\n","\n","# scikit-learn\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtmyxyXM_jhv","executionInfo":{"status":"ok","timestamp":1626347938933,"user_tz":-540,"elapsed":7,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["IMG_MEAN = [0.485, 0.456, 0.406]\n","IMG_STD = [0.229, 0.224, 0.225]\n","\n","class AtmaDataset(data.Dataset):\n","    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n","    object_path_key = \"object_path\"\n","    label_key = \"target\"\n","\n","    @property\n","    def meta_keys(self):\n","        retval = [self.object_path_key]\n","\n","        if self.is_train:\n","            retval += [self.label_key]\n","\n","        return retval\n","\n","    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n","        \"\"\"\n","        args:\n","            meta_df: \n","                画像へのパスと label 情報が含まれている dataframe\n","                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n","            \n","            is_train:\n","                True のとき学習用のデータ拡張を適用します.\n","                False の時は単に size にリサイズを行います\n","        \"\"\"\n","\n","        self.is_train = is_train\n","        self.meta_df = meta_df.reset_index(drop=True)\n","        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n","\n","        size = (224, 224)\n","\n","        additional_items = (\n","            [T.Resize(size)]\n","            if not is_train\n","            else [\n","                T.RandomGrayscale(p=0.2),\n","                T.RandomVerticalFlip(),\n","                T.RandomHorizontalFlip(),\n","                T.RandomResizedCrop(size),\n","            ]\n","        )\n","\n","        self.transformer = T.Compose(\n","            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n","        )\n","\n","    def __getitem__(self, index):\n","        data = self.index_to_data[index]\n","\n","        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n","        img = Image.open(obj_path)\n","        img = self.transformer(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.meta_df)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8_Ouj1v_jhw","executionInfo":{"status":"ok","timestamp":1626347938933,"user_tz":-540,"elapsed":6,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["# CUDA を使うので確認. google colab の場合 GPU accelerator をオンにしておいてください\n","assert torch.cuda.is_available()\n","\n","DEVICE = torch.device(\"cuda\")"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jn5HXYPk_jhw"},"source":["## Train / Validation Phase"]},{"cell_type":"code","metadata":{"id":"mbgHcPuMm5Vf","executionInfo":{"status":"ok","timestamp":1626347938934,"user_tz":-540,"elapsed":7,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["def train(\n","    model: nn.Module,\n","    optimizer: Optimizer,\n","    train_loader: data.DataLoader\n",") -> pd.Series:\n","\n","    # train にすることで model 内の学習時にのみ有効な機構が有効になります (Dropouts Layers、BatchNorm Layers...)\n","    model.train()\n","    \n","    criterion = nn.MSELoss()\n","\n","    # ロスの値を保存する用に dict を用意\n","    metrics = defaultdict(float)\n","    n_iters = len(train_loader)\n","    \n","    for i, (x_i, y_i) in enumerate(train_loader):\n","        x_i = x_i.to(DEVICE)\n","        y_i = y_i.to(DEVICE).reshape(-1, 1).float()\n","\n","        output = model(x_i)\n","        loss = criterion(output, y_i)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        metric_i = {\n","            # loss は tensor object なので item をつかって python object に戻す\n","            \"loss\": loss.item()\n","        }\n","        for k, v in metric_i.items():\n","            metrics[k] += v\n","\n","    for k, v in metrics.items():\n","        metrics[k] /= n_iters\n","\n","    # Series型を作るが、その時すべての列名に接頭語 train_をつける\n","    return pd.Series(metrics).add_prefix(\"train_\")\n","\n","def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n","    # train とは逆で model 内の学習時にのみ有効な機構がオフになります (Dropouts Layers、BatchNorm Layers...)\n","    model.eval()\n","    \n","    predicts = []\n","    \n","    for x_i, y_i in loader:\n","        \n","        # 明示的に勾配を計算しないように指定することができます. \n","        # この関数ではモデルの更新はせずに単に出力だけを使いますので勾配は不要です.\n","        with torch.no_grad():\n","            output = model(x_i.to(DEVICE))\n","\n","        predicts.extend(output.data.cpu().numpy())\n","\n","    pred = np.array(predicts).reshape(-1)\n","    return pred\n","\n","\n","def calculate_metrics(y_true, y_pred) -> dict:\n","    \"\"\"正解ラベルと予測ラベルから指標を計算する\"\"\"    \n","    return {\n","        'rmse': mean_squared_error(y_true, y_pred) ** .5\n","    }\n","\n","\n","def valid(\n","    model: nn.Module, \n","    y_valid: np.ndarray, \n","    valid_loader: data.DataLoader\n",") -> pd.Series:\n","    \"\"\"検証フェーズ\n","    与えられたモデル・データローダを使って検証フェーズを実行。スコアの dict と予測した値を返す\n","    \"\"\"\n","    \n","    pred = predict(model, valid_loader)\n","    score = calculate_metrics(y_valid, pred)\n","\n","    valid_score = pd.Series(score)\n","    return valid_score.add_prefix(\"valid_\"), pred"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QsgHqe3_jhx"},"source":["## Run Fold\n","\n","1. train / valid の loader 作成\n","2. 以下を epoch 数だけ繰り返す\n","    1. 学習用データで学習 \n","    2. 検証用データで検証スコアの算出"]},{"cell_type":"code","metadata":{"id":"vLZrJGPboOfh","executionInfo":{"status":"ok","timestamp":1626347938934,"user_tz":-540,"elapsed":6,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["def get_output_dir(n_cv: int):\n","    return os.path.join(output_dir, 'simple_resnet', f'cv={n_cv}')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fkjANF0NlHye","executionInfo":{"status":"ok","timestamp":1626347939877,"user_tz":-540,"elapsed":948,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["def run_fold(\n","    model: nn.Module, \n","    train_df: pd.DataFrame, \n","    valid_df: pd.DataFrame, \n","    y_valid: np.ndarray, \n","    output_dir: str, \n","    n_epochs=30) -> np.ndarray:\n","    \"\"\"\n","    train / valid に分割されたデータで学習と同時に検証を行なう\n","    \"\"\"\n","    \n","    # 0: \n","    #   : 前準備. dataframe から data loader を作成\n","    train_dataset = AtmaDataset(meta_df=train_df)\n","    train_loader = data.DataLoader(\n","        train_dataset, batch_size=128, shuffle=True, drop_last=True, num_workers=2\n","    )\n","    \n","    #   : 検証用の方は is_train=False にしてデータ拡張オフにする\n","    valid_dataset = AtmaDataset(meta_df=valid_df, is_train=False)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=2)\n","    \n","        # 当Fold(CV#)用のdirを作る\n","    os.makedirs(output_i, exist_ok=True)\n","\n","    # optimizer の定義\n","    optimizer = Adam(model.parameters(), lr=1e-3)\n","\n","    # --- 保存のための変数定義\n","    score_df = pd.DataFrame()\n","    valid_score = np.inf\n","    valid_score_key = \"valid_rmse\"\n","    valid_best_pred = None\n","\n","    for epoch in range(1, n_epochs + 1):\n","        print(f'|||. start epoch = {epoch}.  |||')\n","        \n","        # 1: 学習用データで学習を実行。学習時のロスを取得\n","        score_train = train(model, optimizer, train_loader)\n","\n","        # 2: 検証データでのスコアを計算\n","        score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid=y_valid)\n","\n","        # print(score_valid)\n","\n","        --- 学習のロスと検証スコアの値をデータフレームに追加\n","        # pd.concat : DataFrame , Seriesを連結する\n","        row = pd.concat([score_train, score_valid])\n","        row[\"epoch\"] = epoch\n","        row = pd.DataFrame([row])\n","        # tabulate : 表形式で表示してくれる\n","        # 多分どんどん行が増えてくるはず？ Yes!\n","        # print(tabulate(row, headers=row.columns))\n","        score_df = pd.concat([score_df, row], ignore_index=True)\n","        # ---\n","\n","           \n","        #  今の検証スコアと過去最高のスコアを比較\n","        current_score = score_valid[valid_score_key]\n","        if current_score < valid_score:\n","            # スコア改善したときモデルを保存する\n","            print(f'validation score is improved!! {valid_score:.4f} -> {current_score:.4f}')\n","            torch.save(\n","                model.state_dict(), os.path.join(output_dir, 'model_best.pth')\n","            )\n","            valid_score = current_score\n","            valid_best_pred = y_valid_pred\n","\n","    score_df.to_csv(os.path.join(output_dir, 'score.csv'), index=False)\n","    return valid_best_pred\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JFgYuj_P_jhy"},"source":["### その他\n","\n","モデル作成などの関数定義"]},{"cell_type":"code","metadata":{"id":"n4-RntyD_jhy","executionInfo":{"status":"ok","timestamp":1626347939877,"user_tz":-540,"elapsed":7,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["def create_model():\n","    model = resnet34(pretrained=False)\n","    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n","    return model\n","    \n","def create_metadata(input_df):\n","    out_df = input_df[['object_id']].copy()\n","    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n","    \n","    if \"target\" in input_df:\n","        out_df[\"target\"] = input_df[\"target\"]\n","\n","    return out_df\n","\n","def run_test_predict(model):\n","    test_meta_df = create_metadata(test_df)\n","\n","    # 学習時のデータ拡張はオフにしたいので is_train=False としている\n","    test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n","    test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=2)\n","    \n","    y_pred = predict(model, loader=test_loader)\n","    return y_pred"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EdBLJE5s_jhy"},"source":["## おさらい\n","\n","前回の学習のコード"]},{"cell_type":"code","metadata":{"id":"moVqsKZ_z0iu","executionInfo":{"status":"ok","timestamp":1626347939878,"user_tz":-540,"elapsed":7,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["train_meta_df = create_metadata(train_df)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"0OPa9MTA_jhy","executionInfo":{"status":"ok","timestamp":1626347939880,"user_tz":-540,"elapsed":8,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["# skf = StratifiedGroupKFold(X, y, groups, features, 5, RANDOM_SEED)\n","# oof = np.zeros((len(train_df), ), dtype=np.float32)\n","\n","# for i, (idx_tr, idx_valid) in enumerate(skf):\n","#     print(\"******************************\")\n","#     print(f\"********  cv = {i}   ********\")\n","#     print(\"******************************\")\n","#     output_i = get_output_dir(i)\n","#     model = create_model()\n","#     model.to(DEVICE)\n","    \n","#     # 1. Fold の学習\n","#     oof_i = run_fold(\n","#                 model=model, \n","#                 train_df=train_meta_df.iloc[idx_tr], \n","#                 valid_df=train_meta_df.iloc[idx_valid], \n","#                 y_valid=train_meta_df['target'].values[idx_valid],\n","#                 output_dir = output_i,\n","#                 n_epochs=100\n","#             )\n","    \n","#     oof[idx_valid] = oof_i\n","\n","\n","# # 学習が終了したら各foldの検証予測値を使って、train_df['target']とのrmseを計算する\n","# calculate_metrics(train_df['target'], oof)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bbS16kmN_jhz"},"source":["### TTA\n","\n","test time augmentation の略です。推論を行なう際にも Augmentation を行ってその平均を取る方法のことです。同じ画像をちょっとずらしたものを何回も推論して平均することで性能が上がる場合があります。\n","\n","今回は簡易のため学習時に使うのと同様の augmentation を使っています。(これが一番いいというわけではないです)"]},{"cell_type":"code","metadata":{"id":"ptg7XZp4_jh0","executionInfo":{"status":"ok","timestamp":1626347939880,"user_tz":-540,"elapsed":8,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}}},"source":["from tqdm import tqdm\n","\n","def run_test_predict_TTA(model, n_tta=0):\n","    test_meta_df = create_metadata(test_df)\n","\n","    # n_tta > 0 の時だけデータ拡張を on にする (is_train = True)\n","    is_tta_mode = n_tta > 0\n","    test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=is_tta_mode)\n","    test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=2)\n","    \n","    predictions = []\n","    n_times = 1 if not is_tta_mode else n_tta\n","    print(f\"run #{n_times} times / tta={is_tta_mode}\")\n","    for _ in tqdm(range(n_times)):\n","        y_pred = predict(model, loader=test_loader)\n","        predictions.append(y_pred)\n","    \n","    # axis=0: 行方向\n","    return np.array(predictions).mean(axis=0)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4q3bfUaI2O5Z"},"source":["## TTA 10回"]},{"cell_type":"code","metadata":{"id":"-is80GWA2O5Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626350367650,"user_tz":-540,"elapsed":464085,"user":{"displayName":"三澤雅史","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ehYwgZ7vTk5mpLIwi2U7OWqeVT9fXZpVW5UgCQ=s64","userId":"14592835272630790536"}},"outputId":"0b8399df-1ffc-4387-eada-cdceba5fced1"},"source":["# TTAを使ってテストデータを推論してみる\n","test_predictions = []\n","\n","# for i in range(len(cv)):\n","for i in range(5):\n","    output_i = get_output_dir(i)\n","    \n","    model = resnet34(pretrained=False)\n","    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n","    \n","    model_path = os.path.join(output_i, 'model_best.pth')\n","    model.load_state_dict(torch.load(model_path))\n","    model.to(DEVICE)\n","    \n","    y_pred_i = run_test_predict_TTA(model, 5)\n","    test_predictions.append(y_pred_i)\n","\n","# submission用のファイルを生成\n","# すべての予測の平均値を使う\n","pred_mean = np.array(test_predictions).mean(axis=0)\n","\n","pd.DataFrame({\n","    \"target\": pred_mean\n","}).to_csv(os.path.join(output_dir, \"013__submission.csv\"), index=False)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["run #5 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5/5 [01:32<00:00, 18.51s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["run #5 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5/5 [01:31<00:00, 18.30s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["run #5 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5/5 [01:33<00:00, 18.72s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["run #5 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5/5 [01:31<00:00, 18.23s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["run #5 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 5/5 [01:32<00:00, 18.47s/it]\n"],"name":"stderr"}]}]}